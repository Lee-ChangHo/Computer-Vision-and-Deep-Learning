{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fffcbde1",
   "metadata": {},
   "source": [
    "# 5. 특징점 검출 \n",
    "\n",
    "## 5-1. 해리스 특징점 검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afdd2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# 10 x 10 크기의 배열 생성\n",
    "img=np.array([[0,0,0,0,0,0,0,0,0,0],\n",
    "              [0,0,0,0,0,0,0,0,0,0],\n",
    "              [0,0,0,1,0,0,0,0,0,0],\n",
    "              [0,0,0,1,1,0,0,0,0,0],\n",
    "              [0,0,0,1,1,1,0,0,0,0],\n",
    "              [0,0,0,1,1,1,1,0,0,0],\n",
    "              [0,0,0,1,1,1,1,1,0,0],\n",
    "              [0,0,0,0,0,0,0,0,0,0],\n",
    "              [0,0,0,0,0,0,0,0,0,0],\n",
    "              [0,0,0,0,0,0,0,0,0,0]],dtype=np.float32)\n",
    "\n",
    "# ux, uy는 소벨연산자이며, k는 1D 가우시안 커널\n",
    "# 수평, 수직 미분 이미지를 구하기 위해 먼저 구함.\n",
    "ux=np.array([[-1,0,1]])\n",
    "uy=np.array([-1,0,1]).transpose()\n",
    "k=cv.getGaussianKernel(3,1)\n",
    "g=np.outer(k,k.transpose())\n",
    "\n",
    "# 앞서 구한 소벨 연산자를 이용하여 수평, 수직 미분 이미지를 구함.\n",
    "dy=cv.filter2D(img,cv.CV_32F,uy)\n",
    "dx=cv.filter2D(img,cv.CV_32F,ux)\n",
    "\n",
    "# 가우시안과 합치기 위해 2차 미분 계산\n",
    "dyy=dy*dy\n",
    "dxx=dx*dx\n",
    "dyx=dy*dx\n",
    "\n",
    "# 가우시안과 2차미분 계산값을 합성\n",
    "gdyy=cv.filter2D(dyy,cv.CV_32F,g)\n",
    "gdxx=cv.filter2D(dxx,cv.CV_32F,g)\n",
    "gdyx=cv.filter2D(dyx,cv.CV_32F,g)\n",
    "C=(gdyy*gdxx-gdyx*gdyx)-0.04*(gdyy+gdxx)*(gdyy+gdxx)\n",
    "\n",
    "for j in range(1,C.shape[0]-1):\t\t# 비최대 억제\n",
    "    for i in range(1,C.shape[1]-1):\n",
    "        if C[j,i]>0.1 and sum(sum(C[j,i]>C[j-1:j+2,i-1:i+2]))==8:\n",
    "            img[j,i]=9\t\t\t# 특징점을 원본 영상에 9로 표시\n",
    "                \n",
    "np.set_printoptions(precision=2)\n",
    "print(dy) \n",
    "print(dx) \n",
    "print(dyy) \n",
    "print(dxx) \n",
    "print(dyx) \n",
    "print(gdyy) \n",
    "print(gdxx) \n",
    "print(gdyx) \n",
    "print(C)\t\t\t\t\t# 특징 가능성 맵 \n",
    "print(img)\t\t\t\t\t# 특징점을 9로 표시한 원본 영상 \n",
    "\n",
    "popping=np.zeros([160,160],np.uint8)\t# 화소 확인 가능하게 16배로 확대\n",
    "for j in range(0,160):\n",
    "    for i in range(0,160):\n",
    "        popping[j,i]=np.uint8((C[j//16,i//16]+0.06)*700)  \n",
    "\n",
    "cv.imshow('Image Display2',popping)    \n",
    "cv.waitKey()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc92871",
   "metadata": {},
   "source": [
    "##  5-2.  SIFT 알고리즘\n",
    "\n",
    "### SIFT는 이미지 피라미드를 이용해서 크기 변화에 따른 특징점 검출 문제를 해결한 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2a99b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "img=cv.imread('./Data/mot_color70.jpg') # 영상 읽기\n",
    "gray=cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# SIFT 추출기 생성\n",
    "sift=cv.SIFT_create() \n",
    "# 키 포인트 검출과 서술자 계산\n",
    "kp,des=sift.detectAndCompute(gray,None)\n",
    "\n",
    "# 키 포인트 그리기\n",
    "gray=cv.drawKeypoints(gray,kp,None,flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv.imshow('sift', gray)\n",
    "\n",
    "k=cv.waitKey()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7adbc1",
   "metadata": {},
   "source": [
    "##  5-3. matching \n",
    "\n",
    "### 두 이미지의 특징점들을 matching 시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fad9016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특징점 개수: 231 4096\n",
      "매칭에 걸린 시간: 0.04189109802246094\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "img1=cv.imread('./Data/mot_color70.jpg')[190:350,440:560] # 버스를 크롭하여 모델 영상으로 사용\n",
    "gray1=cv.cvtColor(img1,cv.COLOR_BGR2GRAY)\n",
    "img2=cv.imread('./Data/mot_color83.jpg')\t\t\t     # 장면 영상\n",
    "gray2=cv.cvtColor(img2,cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# SIFT 추출기 생성\n",
    "sift=cv.SIFT_create()\n",
    "# 특징점들을 매칭해보기 위해 각 사진들의 특징점들을 구함\n",
    "kp1,des1=sift.detectAndCompute(gray1,None)\n",
    "kp2,des2=sift.detectAndCompute(gray2,None)\n",
    "print('특징점 개수:',len(kp1),len(kp2)) \n",
    "\n",
    "# 매칭에 걸린 시간을 측정하기위해 time() 함수 사용\n",
    "start=time.time()\n",
    "flann_matcher=cv.DescriptorMatcher_create(cv.DescriptorMatcher_FLANNBASED)\n",
    "\n",
    "# 이미지 1과 이미지 2의 특징점 매칭\n",
    "knn_match=flann_matcher.knnMatch(des1,des2,2)\n",
    "\n",
    "# 특징점 검출 후 올바른 비교값들만 good_match라는 빈 배열에 넣기\n",
    "T=0.7\n",
    "good_match=[]\n",
    "for nearest1,nearest2 in knn_match:\n",
    "    if (nearest1.distance/nearest2.distance)<T:\n",
    "        good_match.append(nearest1)\n",
    "print('매칭에 걸린 시간:',time.time()-start) \n",
    "\n",
    "# 매칭 결과를 시각화 하기 위해 두 이미지 병합 후 매칭되는 특징점들 그려주기\n",
    "img_match=np.empty((max(img1.shape[0],img2.shape[0]),img1.shape[1]+img2.shape[1],3),dtype=np.uint8)\n",
    "cv.drawMatches(img1,kp1,img2,kp2,good_match,img_match,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "cv.imshow('Good Matches', img_match)\n",
    "\n",
    "k=cv.waitKey()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168aaed4",
   "metadata": {},
   "source": [
    "##  5-4. 특징점들을 매칭한 이미지에 특징점으로 매칭 된 부분을 네모 박스 치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66dc2d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img1=cv.imread('./Data/mot_color70.jpg')[190:350,440:560] # 버스를 크롭하여 모델 영상으로 사용\n",
    "gray1=cv.cvtColor(img1,cv.COLOR_BGR2GRAY)\n",
    "img2=cv.imread('./Data/mot_color83.jpg')\t\t\t     # 장면 영상\n",
    "gray2=cv.cvtColor(img2,cv.COLOR_BGR2GRAY)\n",
    "\n",
    "sift=cv.SIFT_create()\n",
    "kp1,des1=sift.detectAndCompute(gray1,None)\n",
    "kp2,des2=sift.detectAndCompute(gray2,None)\n",
    "\n",
    "flann_matcher=cv.DescriptorMatcher_create(cv.DescriptorMatcher_FLANNBASED)\n",
    "knn_match=flann_matcher.knnMatch(des1,des2,2)\t# 최근접 2개\n",
    "\n",
    "T=0.7\n",
    "good_match=[]\n",
    "for nearest1,nearest2 in knn_match:\n",
    "    if (nearest1.distance/nearest2.distance)<T:\n",
    "        good_match.append(nearest1)\n",
    "\n",
    "points1=np.float32([kp1[gm.queryIdx].pt for gm in good_match])\n",
    "points2=np.float32([kp2[gm.trainIdx].pt for gm in good_match])\n",
    "\n",
    "H,_=cv.findHomography(points1,points2,cv.RANSAC)\n",
    "\n",
    "h1,w1=img1.shape[0],img1.shape[1] \t\t# 첫 번째 영상의 크기\n",
    "h2,w2=img2.shape[0],img2.shape[1] \t\t# 두 번째 영상의 크기\n",
    "\n",
    "box1=np.float32([[0,0],[0,h1-1],[w1-1,h1-1],[w1-1,0]]).reshape(4,1,2)\n",
    "box2=cv.perspectiveTransform(box1,H)\n",
    "\n",
    "img2=cv.polylines(img2,[np.int32(box2)],True,(0,255,0),8)\n",
    "\n",
    "img_match=np.empty((max(h1,h2),w1+w2,3),dtype=np.uint8)\n",
    "cv.drawMatches(img1,kp1,img2,kp2,good_match,img_match,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "   \n",
    "cv.imshow('Matches and Homography',img_match)\n",
    "\n",
    "k=cv.waitKey()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec42fb77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
